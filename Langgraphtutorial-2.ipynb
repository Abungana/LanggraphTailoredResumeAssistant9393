{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Hello World Agent"
      ],
      "metadata": {
        "id": "s994phJUmeJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX0fYtsSmSjQ"
      },
      "outputs": [],
      "source": [
        "# Install the langgraph library\n",
        "!pip install langgraph\n",
        "# Import the required classes\n",
        "from typing import Dict, TypedDict\n",
        "from langgraph.graph import StateGraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the state structure\n",
        "class AgentState(TypedDict):\n",
        "    message: str\n",
        "\n",
        "# Define the greeting node as a separate function\n",
        "def greeting_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"simple node that adds a greeting message to the state\"\"\"\n",
        "    state[\"message\"] = \"Hey \" + state[\"message\"] + \", how is your day going?\"\n",
        "    return state"
      ],
      "metadata": {
        "id": "qahsMifFnKMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"greeter\", greeting_node)\n",
        "\n",
        "graph.set_entry_point(\"greeter\")\n",
        "\n",
        "graph.set_finish_point(\"greeter\")\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "DtCQs1r3oPSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Call draw_mermaid_png() on the compiled graph 'app' to get the image data\n",
        "graph_image_data = app.get_graph().draw_mermaid_png()\n",
        "\n",
        "# Pass the image data to the Image constructor and then display it\n",
        "display(Image(graph_image_data))"
      ],
      "metadata": {
        "id": "jVqWcmwMpTIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = app.invoke({\"message\": \"Enock Abungana\"})"
      ],
      "metadata": {
        "id": "0MYlYiMfqUTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['message']"
      ],
      "metadata": {
        "id": "7D1BoV7tqsp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph II"
      ],
      "metadata": {
        "id": "ILQ2a1eyrLY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required classes\n",
        "from typing import Dict, TypedDict, List\n",
        "from langgraph.graph import StateGraph"
      ],
      "metadata": {
        "id": "tYbkONSHrQH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import name\n",
        "class AgentState(TypedDict):\n",
        "    values: List[int]\n",
        "    name: str\n",
        "    result: str"
      ],
      "metadata": {
        "id": "QNV2iCCbrgch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_values(state: AgentState) -> AgentState:\n",
        "    \"\"\"simple node that adds a greeting message to the state\"\"\"\n",
        "    state[\"result\"] = str(sum(state[\"values\"]))\n",
        "    return state"
      ],
      "metadata": {
        "id": "IE4Ry0Pkr_W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"processor\", process_values)\n",
        "\n",
        "graph.set_entry_point(\"processor\")\n",
        "\n",
        "graph.set_finish_point(\"processor\")\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "EMLhbeYcsM3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Call draw_mermaid_png() on the compiled graph 'app' to get the image data\n",
        "graph_image_data = app.get_graph().draw_mermaid_png()"
      ],
      "metadata": {
        "id": "EbGZvJKAsiu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-community langgraph openai faiss-cpu\n"
      ],
      "metadata": {
        "id": "yZZP648TwuwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "SspHOQGRxQBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install dependencies (once; run in your notebook or terminal):\n",
        "#    %pip install -qU langgraph langchain langchain-community langchain-openai openai faiss-cpu typing-extensions\n",
        "\n",
        "import os\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# 2. Helper to chunk text\n",
        "def split_text(text: str, chunk_size: int = 1500) -> list[str]:\n",
        "    return [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "# 3. Define shared state schema\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    resume_chunks: list[str]\n",
        "    jd_text: str\n",
        "    top_sections: list[str]\n",
        "    rewritten_bullets: str\n",
        "    cover_letter: str\n",
        "\n",
        "# 4. Node implementations\n",
        "\n",
        "def load_documents(state: State) -> State:\n",
        "    # Dummy text so we don’t hit file errors\n",
        "    dummy_resume = \"\"\"\n",
        "    • Designed and deployed a CNN model for flood prediction in Sudan, achieving 85% accuracy.\n",
        "    • Built an Airflow ETL pipeline to ingest and process GIS settlement data daily.\n",
        "    • Collaborated with UNHCR to develop a displacement-forecasting dashboard serving 3 million+ individuals.\n",
        "    \"\"\"\n",
        "    dummy_jd = \"\"\"\n",
        "    We are seeking a Data Scientist to build LLM-powered workflows that integrate vector search,\n",
        "    FAISS, and Python. Experience with iterative agent-based design and multi-step pipelines is a plus.\n",
        "    \"\"\"\n",
        "    state[\"resume_chunks\"] = split_text(dummy_resume)\n",
        "    state[\"jd_text\"] = dummy_jd.strip()\n",
        "    return state\n",
        "\n",
        "def retrieve_relevant_sections(state: State) -> State:\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    emb = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "    vect = FAISS.from_documents(state[\"resume_chunks\"], emb)\n",
        "    docs = vect.similarity_search(state[\"jd_text\"], k=5)\n",
        "    state[\"top_sections\"] = [doc.page_content for doc in docs]\n",
        "    return state\n",
        "\n",
        "def rewrite_for_target(state: State) -> State:\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    llm = OpenAI(temperature=0.2, openai_api_key=api_key)\n",
        "    prompt = (\n",
        "        \"Rewrite these résumé bullets to match the tone, keywords, and style of the job description below.\\n\\n\"\n",
        "        f\"Job Description:\\n{state['jd_text']}\\n\\n\"\n",
        "        \"Résumé Sections:\\n\" + \"\\n\".join(state[\"top_sections\"])\n",
        "    )\n",
        "    state[\"rewritten_bullets\"] = llm(prompt)\n",
        "    return state\n",
        "\n",
        "def assemble_output(state: State) -> State:\n",
        "    state[\"cover_letter\"] = (\n",
        "        \"Dear Hiring Manager,\\n\\n\"\n",
        "        \"I am excited to apply for this position because…\\n\\n\"\n",
        "        f\"{state['rewritten_bullets']}\\n\\n\"\n",
        "        \"Thank you for your consideration.\\n\\n\"\n",
        "        \"Sincerely,\\nYour Name\"\n",
        "    )\n",
        "    return state\n",
        "\n",
        "# 5. Build and compile the graph\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(load_documents)\n",
        "builder.add_node(retrieve_relevant_sections)\n",
        "builder.add_node(rewrite_for_target)\n",
        "builder.add_node(assemble_output)\n",
        "\n",
        "builder.set_entry_point(\"load_documents\")\n",
        "builder.add_edge(START,                    \"load_documents\")\n",
        "builder.add_edge(\"load_documents\",        \"retrieve_relevant_sections\")\n",
        "builder.add_edge(\"retrieve_relevant_sections\", \"rewrite_for_target\")\n",
        "builder.add_edge(\"rewrite_for_target\",    \"assemble_output\")\n",
        "builder.add_edge(\"assemble_output\",       END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "# 6. Execute\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure your OPENAI_API_KEY is set, e.g.:\n",
        "    #   export OPENAI_API_KEY=\"sk-…\"\n",
        "    initial_state: State = {\n",
        "        \"messages\": [],\n",
        "        \"resume_chunks\": [],\n",
        "        \"jd_text\": \"\",\n",
        "        \"top_sections\": [],\n",
        "        \"rewritten_bullets\": \"\",\n",
        "        \"cover_letter\": \"\",\n",
        "    }\n",
        "    result = graph.invoke(initial_state)\n",
        "    print(\"\\n--- Generated Cover Letter ---\\n\")\n",
        "    print(result[\"cover_letter\"])\n"
      ],
      "metadata": {
        "id": "DPX7Sk_RzCe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##bash API Key set up\n",
        "export OPENAI_API_KEY=\"your_openai_key_here\"\n",
        "\n"
      ],
      "metadata": {
        "id": "jTUc95gqzDg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}